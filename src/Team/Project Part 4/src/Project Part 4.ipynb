{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Part 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import plotly.figure_factory as ff\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from pandas.plotting import autocorrelation_plot\n",
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File ../data/owid-covid-data.csv does not exist: '../data/owid-covid-data.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-259-2ec2def30504>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#import datasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmain_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/owid-covid-data.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlarge_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../data/covid_large.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#obtain only the information for the USA\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File ../data/owid-covid-data.csv does not exist: '../data/owid-covid-data.csv'"
     ]
    }
   ],
   "source": [
    "#import datasets\n",
    "main_data = pd.read_csv(\"../data/owid-covid-data.csv\")\n",
    "large_data = pd.read_csv(\"../data/covid_large.csv\")\n",
    "\n",
    "#obtain only the information for the USA\n",
    "USA_main_data = main_data.loc[main_data['iso_code'] == 'USA']\n",
    "\n",
    "#reset index of the dataset\n",
    "USA_main_data = USA_main_data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain only the needed columns\n",
    "main_graph = USA_main_data[['date', 'new_cases', 'new_cases_per_million', 'new_deaths', 'new_deaths_per_million']]\n",
    "\n",
    "#rename columns\n",
    "main_graph.columns = ['Date', 'New Cases', 'New Cases (log)', 'New Deaths', 'New Deaths (log)']\n",
    "\n",
    "#display dataset for task 1\n",
    "main_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain the date of the first case\n",
    "first_case_index = main_graph['New Cases'].ne(0).idxmax() \n",
    "\n",
    "#obtain the date of the first death\n",
    "first_death_index= main_graph['New Deaths'].ne(0).idxmax() \n",
    "\n",
    "#list to hold the cases since day 1\n",
    "numOfCasesSinceDay1=[]\n",
    "\n",
    "#list to hold the deaths since day 1\n",
    "numOfDeathsSinceDay1=[]\n",
    "\n",
    "#loop to compute the number of cases since day 1\n",
    "counter=1\n",
    "for i,index in enumerate(range(len(main_graph))):\n",
    "    if i<=first_case_index:\n",
    "        numOfCasesSinceDay1.insert(index, 0) \n",
    "    else:\n",
    "        numOfCasesSinceDay1.insert(index, counter) \n",
    "        counter = counter+1\n",
    "\n",
    "#loop to compute the number of deaths since day 1\n",
    "counter=1\n",
    "for i,index in enumerate(range(len(main_graph))):\n",
    "    if i<=first_death_index:\n",
    "        numOfDeathsSinceDay1.insert(index, 0) \n",
    "    else:\n",
    "        numOfDeathsSinceDay1.insert(index, counter) \n",
    "        counter = counter+1\n",
    "\n",
    "#insert list into dataset as a column\n",
    "main_graph.insert(2, \"numOfCasesSinceDay1\", numOfCasesSinceDay1)\n",
    "\n",
    "#insert list into dataset as a column   \n",
    "main_graph.insert(2, \"numOfDeathsSinceDay1\", numOfDeathsSinceDay1)\n",
    "\n",
    "#print dataset\n",
    "main_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtain the Regression Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain x from the dataset as the number of cases since day 1\n",
    "X = main_graph.iloc[:,3].values.reshape(-1, 1) \n",
    "\n",
    "#obtain y from the dataset as the number of cases per day\n",
    "y = main_graph.iloc[:,1].values.reshape(-1, 1)\n",
    "\n",
    "#create regression for a polynomial of degree 3\n",
    "poly3 = PolynomialFeatures(degree = 3)\n",
    "poly_features3 = poly3.fit_transform(X)\n",
    "poly3.fit(X,y)\n",
    "poly_regression3 = LinearRegression()\n",
    "poly_regression3.fit(poly_features3,y)\n",
    "\n",
    "#insert list into dataset as a column\n",
    "regression = poly_regression3.predict(poly_features3)\n",
    "main_graph.insert(2, \"Polynomial Case Model Prediction\", regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain x from the dataset as the number of cases since day 1\n",
    "X = main_graph.iloc[:,3].values.reshape(-1, 1) \n",
    "\n",
    "#obtain y from the dataset as the number of cases per day\n",
    "y = main_graph.iloc[:,4].values.reshape(-1, 1)\n",
    "\n",
    "#create regression for a polynomial of degree 3\n",
    "poly3 = PolynomialFeatures(degree = 3)\n",
    "poly_features3 = poly3.fit_transform(X)\n",
    "poly3.fit(X,y)\n",
    "poly_regression3 = LinearRegression()\n",
    "poly_regression3.fit(poly_features3,y)\n",
    "\n",
    "#insert list into dataset as a column\n",
    "regression = poly_regression3.predict(poly_features3)\n",
    "main_graph.insert(2, \"Polynomial Case Model Prediction (log)\", regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain x from the dataset as the number of deaths since day 1\n",
    "X = main_graph.iloc[:,2].values.reshape(-1, 1) \n",
    "\n",
    "#obtain y from the dataset as the number of deaths per day\n",
    "y = main_graph.iloc[:,5].values.reshape(-1, 1)\n",
    "\n",
    "#create regression for a polynomial of degree 3\n",
    "poly3 = PolynomialFeatures(degree = 3)\n",
    "poly_features3 = poly3.fit_transform(X)\n",
    "poly3.fit(X,y)\n",
    "poly_regression3 = LinearRegression()\n",
    "poly_regression3.fit(poly_features3,y)\n",
    "\n",
    "#insert list into dataset as a column\n",
    "regression = poly_regression3.predict(poly_features3)\n",
    "main_graph.insert(2, \"Polynomial Death Model Prediction\", regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain x from the dataset as the number of deaths since day 1\n",
    "X = main_graph.iloc[:,2].values.reshape(-1, 1) \n",
    "\n",
    "#obtain y from the dataset as the number of deaths per day\n",
    "y = main_graph.iloc[:,6].values.reshape(-1, 1)\n",
    "\n",
    "#create regression for a polynomial of degree 3\n",
    "poly3 = PolynomialFeatures(degree = 3)\n",
    "poly_features3 = poly3.fit_transform(X)\n",
    "poly3.fit(X,y)\n",
    "poly_regression3 = LinearRegression()\n",
    "poly_regression3.fit(poly_features3,y)\n",
    "\n",
    "#insert list into dataset as a column\n",
    "regression = poly_regression3.predict(poly_features3)\n",
    "main_graph.insert(2, \"Polynomial Death Model Prediction (log)\", regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop unneeded columns\n",
    "main_graph = main_graph.drop(['numOfDeathsSinceDay1', 'numOfCasesSinceDay1'],axis=1)\n",
    "\n",
    "#display final dataset\n",
    "main_graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dash Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#make a dash app\n",
    "app = JupyterDash(__name__)\n",
    "\n",
    "#set the layout for the dash app\n",
    "app.layout = html.Div([\n",
    "    \n",
    "     #name for the dash app\n",
    "     html.H1(\"USA Covid Data\", style = {'text_align' : 'center'}),\n",
    "    \n",
    "    #make a dropdown object to hold the differnt graph options\n",
    "    dcc.Dropdown(\n",
    "        \n",
    "        #name of the object\n",
    "        id = 'dropdown', \n",
    "        \n",
    "        #the options for the dropdown menu\n",
    "        options = [\n",
    "            {'label': 'New Cases (linear)', 'value': 'New Cases (linear)'},\n",
    "            {'label': 'New Deaths (linear)', 'value': 'New Deaths (linear)'},\n",
    "            {'label': 'New Cases (log)', 'value': 'New Cases (log)'},\n",
    "            {'label': 'New Deaths (log)', 'value':'New Deaths (log)'}],\n",
    "        \n",
    "        #initial value of the dropdown menu\n",
    "        value = 'New Cases (linear)',\n",
    "        \n",
    "        #disable mutiple choices\n",
    "        multi = False,\n",
    "        \n",
    "        #disable empty choices\n",
    "        clearable = False,\n",
    "        \n",
    "        #design the style of the dropdown menu\n",
    "        style = {'width': \"100%\", 'text-align': 'center'}),\n",
    "    \n",
    "    #graph object\n",
    "    dcc.Graph(id = 'graph'),\n",
    "    \n",
    "    #object for the range slider\n",
    "    dcc.RangeSlider(\n",
    "        \n",
    "        #name of the range slider\n",
    "        id='range-slider',\n",
    "        \n",
    "        #min value of the range slider\n",
    "        min = '2019-12-31',\n",
    "        \n",
    "        #max value of the range slider\n",
    "        max = '2020-10-12',\n",
    "        \n",
    "        #initial value of teh range slider\n",
    "        value = ['2019-12-31', '2020-10-12'],\n",
    "        \n",
    "        #marks on the range slider that correspond to the dates\n",
    "        marks = {x: x for x in main_graph['Date']}\n",
    "    )\n",
    "])\n",
    "\n",
    "\n",
    "#callback to connect dash with plotyly\n",
    "@app.callback(\n",
    "    Output('graph', 'figure'),\n",
    "    [Input('dropdown', 'value'),\n",
    "    Input('range-slider', 'value')]\n",
    ")\n",
    "\n",
    "#function to update the graph\n",
    "def update_figure(column, dates):\n",
    "    \n",
    "    #obtain the range of dates specified by the range slider\n",
    "    df = main_graph[(main_graph['Date'] >= dates[0]) & (main_graph['Date'] <= dates[1])]\n",
    "    \n",
    "    #conditional statements to display appropriate graphs depending on the dropdown menu selection\n",
    "    if column == 'New Cases (linear)':\n",
    "        return px.line(df, x = 'Date', y = [df.columns[1], df.columns[5]], labels = {'value' : ' New Cases'})\n",
    "    elif column == 'New Deaths (linear)':\n",
    "        return px.line(df, x = 'Date', y = [df.columns[7], df.columns[3]], labels = {'value' : ' New Deaths'})\n",
    "    elif column == 'New Cases (log)':\n",
    "        return px.line(df, x = 'Date', y = [df.columns[6], df.columns[4]], labels = {'value' : ' New Cases (log)'})\n",
    "    else:\n",
    "        return px.line(df, x = 'Date', y = [df.columns[8], df.columns[2]], labels = {'value' : ' New Deaths (log)'})\n",
    "    \n",
    "#run dash app\n",
    "app.run_server(mode = 'inline')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain the dates and new cases\n",
    "df_cases_7da = USA_main_data[['date','new_cases']]\n",
    "\n",
    "#calculate rolling mean and convert to column in the dataset\n",
    "df_cases_7da['MA'] = df_cases_7da.rolling(window=7).mean()\n",
    "\n",
    "#display dataset\n",
    "df_cases_7da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the plot of the rolling average cases\n",
    "fig = px.line(df_cases_7da, x = \"date\", y = [df_cases_7da.columns[1], df_cases_7da.columns[2]], title ='COVID-19 Cases USA 7 Day Rolling Average')\n",
    "\n",
    "#display plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset to hold the new deaths information\n",
    "df_deaths_7da = USA_main_data[['date','new_deaths']]\n",
    "\n",
    "#obtain rolling mean\n",
    "df_deaths_7da['MA'] = df_deaths_7da.rolling(window=7).mean()\n",
    "\n",
    "#display dataset\n",
    "df_deaths_7da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make the plot of the rolling average deaths\n",
    "fig = px.line(df_deaths_7da, x = \"date\", y = [df_deaths_7da.columns[1], df_deaths_7da.columns[2]], title ='COVID-19 Deaths USA 7 Day Rolling Average')\n",
    "\n",
    "#display plot\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obtain recent data\n",
    "recent_data = large_data.loc[large_data['Date'] == '2020-11-27']\n",
    "\n",
    "#make and display test plot\n",
    "fig = ff.create_choropleth(fips=recent_data['countyFIPS'], values=recent_data['Num of Cases'])\n",
    "fig.layout.template = None\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
